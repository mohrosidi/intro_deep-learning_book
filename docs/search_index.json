[
["index.html", "Pengenalan Deep Learning Pengantar", " Pengenalan Deep Learning Mohammad Rosidi 2020-03-05 Pengantar body{ text-align: justify} "],
["intro.html", "Chapter 1 Pengantar Deep Learning", " Chapter 1 Pengantar Deep Learning Proses pegerjaan "],
["DL.html", "Chapter 2 Konsep Proses Pembelajaran Deep Learning", " Chapter 2 Konsep Proses Pembelajaran Deep Learning body{ text-align: justify} Proses pembelajaran Artificial Neural Network (ANN) pada dasarnya digunakan untuk mencari nilai bobot (\\(w\\)) optimal yang menghubungkan antar lapisan neuron sehingga diperoleh cost atau kesalahan minimum. Proses pembelajaran pada ANN dilakukan melalui dua proses utama, antara lain: Propagasi maju (forward propagation) Propagasi mundur (bacward propagation) Secara umum propagasi maju proses dimana ANN memproses input data untuk melakukan prediksi terhadap nilai variabel target. Tahapan ini melibatkan proses perkalian titik antara input dan bobot dan pemjumlahan dengan bias dari masing-masing layer ANN. Hasil penjumlahan selanjutnya transformasi melalui fungsi aktivasi. Pada awal proses pembelajaran, bobot dat bias pada tiap jaringan ditetapkan secara acak, sehingga jaringan mengimplementasikan serangkaian transformasi secara acak. Hal ini menyebabkan nilai output yang dihasilkan jauh dari nilai yang diharapkan atau cost yang dihasilkan sangat tinggi. Untuk mengatasi cost yang tinggi tersebut, bobot dilakukan penyesuaian sehingga pada proses pembelajaran selanjutnya nilai cost yang dihasilkan menurun. Proses tersebut diulangi secara terus-menerus hingga diperoleh cost minimum yang konvergen. Tahapan tersebut disebut sebagai tahapan propagasi balik. Pada tahapan ini, hasil prediksi dari proses propagasi balik dihitung nilai cost-nya (error). Nilai tersebut selanjutnya dijadikan sebagai dasar dalam melakukan penyesuaian bobot dan bias pada ANN. Gambaran proses pembelajaran ditampilkan pada Gambar 2.1. Gambar 2.1: Proses pembelajaran ANN. (Sumber:Chollet, 2018) "],
["notation.html", "2.1 Notasi Matematika", " 2.1 Notasi Matematika Terdapat sejumlah notasi matematika yang akan digunakan dalam pembahasan Chapter ini. Notasi matematika tersebut antara lain: Untuk input \\(x \\in R^{n_x}\\) (\\(n\\) variabel atau fitur) superskrip (\\(i\\)): menunjukkan referensi observasi ke-\\(i\\), contoh: \\(x^{\\left(2\\right)}\\) merupakan nilai input pada observasi atau baris kedua. subskrip \\(n\\) : menunjukkan referensi fitur atau variabel ke-\\(n\\), contoh: \\(x^{\\left(2\\right)}_{1}\\) merupakan observasi kedua pada fitur pertama. Untuk network layer: superskrip [\\(I\\)]: menunjukkan referensi layer ke-\\(I\\), contoh: \\(z^{\\left[2\\right]}\\) merupakan fungsi aktivasi pada layer 2. subskrip \\(n\\) : menunjukkan referensi node atau neuron ke-\\(n\\), contoh: \\(z^{\\left[2\\right]}_{1}\\) merupakan fungsi aktivasi ditambah bias pada node 1 pada layer 2. "],
["forwardprop.html", "2.2 Konsep Propagasi Maju", " 2.2 Konsep Propagasi Maju body{ text-align: justify} Input sebuah model ANN dapat berupa apapun. Input dapat berupa intensitas abu-abu (bernilai 0 dan 1) dari sebuah gambar berukuran 30 x 30 pixel. Pada kasus gambar tersebut, kita dapat memiliki 900 unit input atau fitur yang merupakan setiap unit pixel yang dimiliki oleh gambar. Gambar 2.2 menampilkan contoh ANN dengan 4 fitur, 2 hiden layer dan satu neuron output. Gambar 2.2: Contoh ANN dengan 4 fitur, 2 hiden layer dan satu neuron output Gambar 2.3 menampilkan representasi sebuah proses transformasi data melalui sebuah neuron pada hidden layer. Gambar 2.3: Representasi sebuah neuron pada lapisan hidden layer Seperti yang telah dijabarkan sebelumnya, pada proses propagasi maju, matks riinput data akan melalui proses perkalian dot terhadap matriks bobotnya (masing-masing input dikalikan dengan bobot dan dijumlahkan seluruhnya). Hasil yang diperoleh selanjutnya dijumlahkan dengan bias. Bias mirip dengan intersep yang ditambahkan dalam persamaan linear. Selain itu, bias merupakan parameter tambahan di ANN yang digunakan untuk menyesuaikan output bersama dengan jumlah bobot input ke neuron. Selain itu, nilai bias memungkinkan kita untuk menggeser fungsi aktivasi ke kanan atau kiri. Dengan demikian, Bias adalah konstanta yang membantu model untuk memproses input data dengan cara yang paling sesuai untuk data yang diberikan. Hasil transformasi data selanjutnya menjadi input bagi layer selanjutnya. Pada tahapan akhir proses propagasi maju, fungsi cost dihitung dengan membandingkan nilai hasil prediksi dengan nilai aktual serta menghitung nilai jarak antara kedua nilai tersebut. Fungsi cost berguna untuk melihat sejauh mana model ANN menangkap pola dalam data. 2.2.1 Matriks Input Misalkan terdapat sebuah persamaan linier dengan jumlah fitur \\(n\\) : \\[\\begin{equation} y^{\\left(i\\right)}=w_0+w_1x_1^{\\left(i\\right)}+w_2x_2^{\\left(i\\right)}+\\cdots+w_nx_n^{\\left(i\\right)}+\\epsilon_i^{\\left(i\\right)}\\ \\ untuk\\ i=1,\\dots,m \\tag{2.1} \\end{equation}\\] Kita dapat merepresentasikan Persamaan (2.1) ke dalam notasi matriks yang ditunjukkan pada Persamaan (2.2) \\[\\begin{equation} \\begin{split} \\begin{bmatrix} y_1 \\\\[0.3em] y_2 \\\\[0.3em] \\vdots \\\\[0.3em] y_m \\end{bmatrix} &amp; = \\begin{bmatrix} 1 &amp; x_{1}^{\\left(1\\right)} &amp; x_{1}^{\\left(1\\right)} &amp; \\cdots &amp; x_{n}^{\\left(1\\right)} \\\\[0.3em] 1 &amp; x_{1}^{\\left(2\\right)} &amp; x_{1}^{\\left(2\\right)} &amp; \\cdots &amp; x_{n}^{\\left(2\\right)} \\\\[0.3em] \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\[0.3em] 1 &amp; x_{1}^{\\left(m\\right)} &amp; x_{1}^{\\left(m\\right)} &amp; \\cdots &amp; x_{n}^{\\left(m\\right)} \\\\[0.3em] \\end{bmatrix} \\begin{bmatrix} w_1 \\\\[0.3em] w_2 \\\\[0.3em] \\vdots \\\\[0.3em] w_m \\end{bmatrix} + \\begin{bmatrix} \\epsilon_1 \\\\[0.3em] \\epsilon_2 \\\\[0.3em] \\vdots \\\\[0.3em] \\epsilon_m \\end{bmatrix} \\\\ &amp; = \\begin{bmatrix} w_1 &amp; w_2 &amp; \\cdots &amp; w_m \\end{bmatrix} \\begin{bmatrix} 1 &amp; 1 &amp; \\cdots &amp; 1 \\\\[0.3em] x_{1}^{\\left(2\\right)} &amp; x_{1}^{\\left(2\\right)} &amp; \\cdots &amp; x_{n}^{\\left(m\\right)} \\\\[0.3em] \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\[0.3em] x_{n}^{\\left(2\\right)} &amp; x_{n}^{\\left(2\\right)} &amp; \\cdots &amp; x_{n}^{\\left(m\\right)} \\\\[0.3em] \\end{bmatrix} + \\begin{bmatrix} \\epsilon_1 \\\\[0.3em] \\epsilon_2 \\\\[0.3em] \\vdots \\\\[0.3em] \\epsilon_m \\end{bmatrix} \\end{split} \\tag{2.2} \\end{equation}\\] Jika error \\(\\epsilon\\) pada Persamaan (2.1) dan Persamaan (2.2) diabaikan maka persamaan yang terbentuk adalah Persamaan (2.3). \\[\\begin{equation} Y = W^{T} X \\tag{2.3} \\end{equation}\\] Dimensi matriks input berdasarkan Persamaan (2.3) adalah (jumlah fitur, jumlah observasi). Misalkan terdapat sebuah model ANN seperti yang ditunjukkan pada Gambar 2.2 dengan 4 fitur dan 2 observasi, maka matriks input pada model tersebut dapat dituliskan sebagai berikut: \\[\\begin{equation} X = \\begin{bmatrix} X_1 &amp; X_2 \\end{bmatrix} = \\begin{bmatrix} x_{1}^{\\left(1\\right)} &amp; x_{1}^{\\left(2\\right)} \\\\[0.3em] x_{2}^{\\left(1\\right)} &amp; x_{2}^{\\left(2\\right)} \\\\[0.3em] x_{3}^{\\left(1\\right)} &amp; x_{3}^{\\left(2\\right)} \\\\[0.3em] x_{4}^{\\left(1\\right)} &amp; x_{4}^{\\left(2\\right)} \\\\[0.3em] \\end{bmatrix} \\end{equation}\\] 2.2.2 Matriks Bias Secara umum dimensi matriks bias adalah (jumlah node pada layer \\(z^{\\left[l\\right]}\\), 1). Pada Gambar 2.2, dimensi matriks bias hidden layer 1 adalah (3,1) karena terdapat 3 buah node pada layer tersebut. Matriks bias pada hidden layer 1 dapat dituliskan sebagai berikut: \\[\\begin{equation} b^{\\left[1\\right]} = \\begin{bmatrix} r \\\\[0.3em] s \\\\[0.3em] t \\end{bmatrix} \\end{equation}\\] Dimensi matriks bias pada hidden layer 2 dapat dituliskan sebagai berikut; \\[\\begin{equation} b^{\\left[1\\right]} = \\begin{bmatrix} u \\\\[0.3em] v \\\\[0.3em] w \\end{bmatrix} \\end{equation}\\] 2.2.3 Matriks Bobot Dimensi matriks bobot ditentukan oleh jumlah node pada layer awal dan pada layer selanjutnya. Sebagai Contoh pada Gambar 2.2, matriks bobot dari input layer menuju hidden layer 1 memiliki dimensi (4,2), matriks bobot dari hidden layer 1 menuju hidden layer 2 memiliki dimensi (3,3), dan matriks bobot dari hidden layer 2 menuju output layer memiliki dimensi (3,1). Berdasarkan contoh tersebut, dimensi matriks bobot dapat digeneralisasi menjadi (jumlah node ke-(l-1), jumlah node ke-l). 2.2.4 Fungsi Aktivasi Setelah dilakukan penambahan bias pada hasil perkalian titik, generalisasi proses perkalian titik input pada tiap hidden layer dapat dinyatakan melalui Persamaan (2.4): \\[\\begin{equation} Z^{\\left[l\\right]}=W^{\\left[l\\right]T} A^{\\left[l-1\\right]} + b^{\\left[l\\right]} \\tag{2.4} \\end{equation}\\] Sebagai contoh perkalian titik pada hidden layer 1 berdasarkan Gambar 2.2 dapat dituliskan sebagai berikut: \\[\\begin{equation} Z^{\\left[1\\right]}=W^{\\left[1\\right]T} X + b^{\\left[1\\right]} \\tag{2.4} \\end{equation}\\] dimana \\(X\\) merupakan input pada hidden layer 1, dan \\(Z^{\\left[l\\right]}\\) merupakan input menuju hidden layer selanjutnya. Secara umum \\(Z^{\\left[l\\right]}\\) memiliki dimensi (jumlah node pada hidden layer l, jumlah observasi). Pada contoh input pada Gambar 2.2, \\(Z^{\\left[1\\right]}\\) memiliki dimensi (3,2). Persamaan \\(Z^{\\left[1\\right]}\\) dapat dituliskan ke dalam notasi matriks berikut: \\[\\begin{equation} \\begin{split} Z^{\\left[1\\right]} &amp; = \\begin{bmatrix} w_{11} &amp; w_{12} &amp; w_{13} \\\\[0.3em] w_{21} &amp; w_{22} &amp; w_{23} \\\\[0.3em] w_{31} &amp; w_{32} &amp; w_{33} \\\\[0.3em] w_{41} &amp; w_{42} &amp; w_{43} \\end{bmatrix} \\begin{bmatrix} x_{1}^{\\left(1\\right)} &amp; x_{1}^{\\left(2\\right)} \\\\[0.3em] x_{2}^{\\left(1\\right)} &amp; x_{2}^{\\left(2\\right)} \\\\[0.3em] x_{3}^{\\left(1\\right)} &amp; x_{3}^{\\left(2\\right)} \\\\[0.3em] x_{4}^{\\left(1\\right)} &amp; x_{4}^{\\left(2\\right)} \\\\[0.3em] \\end{bmatrix} + \\begin{bmatrix} r \\\\[0.3em] s \\\\[0.3em] t \\end{bmatrix} &amp; = \\begin{bmatrix} z_{1,1}^{\\left[1\\right]} &amp; z_{1,2}^{\\left[1\\right]} \\\\[0.3em] z_{2,1}^{\\left[1\\right]} &amp; z_{2,2}^{\\left[1\\right]} \\\\[0.3em] z_{3,1}^{\\left[1\\right]} &amp; z_{3,2}^{\\left[1\\right]} \\\\[0.3em] \\end{bmatrix} \\end{split} \\end{equation}\\] Fungsi aktivasi \\(A^{\\left[1\\right]}\\) memiliki dimensi yang sama dengan \\(Z^{\\left[1\\right]}\\) dan dituliskan ke dalam notasi matriks berikut: \\[\\begin{equation} \\begin{bmatrix} g\\left(z_{1,1}^{\\left[1\\right]}\\right) &amp; g\\left(z_{1,2}^{\\left[1\\right]}\\right) \\\\[0.3em] g\\left(z_{2,1}^{\\left[1\\right]}\\right) &amp; g\\left(z_{2,2}^{\\left[1\\right]}\\right) \\\\[0.3em] g\\left(z_{3,1}^{\\left[1\\right]}\\right) &amp; g\\left(z_{3,2}^{\\left[1\\right]}\\right) \\\\[0.3em] \\end{bmatrix} \\end{equation}\\] dimana \\(g\\) merupakan sebuah fungsi aktivasi (contoh: sigmoid, linier, dll.). Matriks \\(A^{\\left[1\\right]}\\) selanjutnya menjadi matriks input pada hidden layer 2. Perkalian titik pada hidden layer 2 dapat dituliskan ke dalam persamaan berikut: "],
["initialization.html", "Chapter 3 Inisialisasi Parameter ANN", " Chapter 3 Inisialisasi Parameter ANN "],
["optimization.html", "Chapter 4 Optimasi Model ANN", " Chapter 4 Optimasi Model ANN "],
["referensi.html", "Referensi", " Referensi body{ text-align: justify} Fox, J. 2005. The R Commander: A Basic-Statistics Graphical User Interface to R. Journal of Statistical Software.Vol:14(9), p:1-42. Fox, J. 2017. Using the R Commader: A Point-and-Click Interface for R. CRC Press. Fox, J. Valat, M.B. 2018. Getting Started With the R Commander.https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/Getting-Started-with-the-Rcmdr.pdf. Gio, P.U. Irawan, D.E. 2016. Belajar Statistika dengan R (disertai beberapa contoh perhitungan manual). USU Press : Medan. Nguyen-Feng, V. Stellmack, M.A. 2016. A Guide to Data Aalysis in R Commander. University of Minnesota. Primartha, R. 2018. Belajar Machine Learning Teori dan Praktik. Penerbit Informatika : Bandung. Quick-R. Data Input. https://www.statmethods.net/input/index.html Quick-R. Data Management. https://www.statmethods.net/management/index.html Rosadi,D. 2011. Analisis Ekonometrika dan Runtun Waktu Terapan dengan R. Penerbit Andi: Yogyakarta. Rosadi,D. 2016. Analisis Statistika dengan R. Gadjah Mada University Press: Yogyakarta. Rosidi, M. 2019. Metode Numerik Menggunakan R Untuk Teknik Lingkungan. https://bookdown.org/moh_rosidi2610/Metode_Numerik/. STHDA. Importing Data Into R . http://www.sthda.com/english/wiki/importing-data-into-r STHDA. Exporting Data From R. http://www.sthda.com/english/wiki/exporting-data-from-r STDHA. Getting Help With Functions In R Programming. http://www.sthda.com/english/wiki/getting-help-with-functions-in-r-programming . Venables, W.N. Smith D.M. and R Core Team. 2018. An Introduction to R. R Manuals. Wickham, H. Grolemund G. 2016. R For Data Science: Import, Tidy, Transform, Visualize, And Model Data. Oâ€™Reilly Media, Inc. Widodo, B. Rachmawati, R.N. 2013. Pengantar Praktis Pemrograman R untuk Ilmu Komputer. Halaman Moeka Publishing : Jakarta. "]
]
