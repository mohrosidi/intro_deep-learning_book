<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.2 Konsep Propagasi Maju | Pengenalan Deep Learning</title>
  <meta name="description" content="Buku ini merupakan reading suplement untuk kursus pengenalan deep learning." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="2.2 Konsep Propagasi Maju | Pengenalan Deep Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Buku ini merupakan reading suplement untuk kursus pengenalan deep learning." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.2 Konsep Propagasi Maju | Pengenalan Deep Learning" />
  
  <meta name="twitter:description" content="Buku ini merupakan reading suplement untuk kursus pengenalan deep learning." />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Mohammad Rosidi" />


<meta name="date" content="2020-03-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="notation.html"/>
<link rel="next" href="initialization.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro to Deep Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Pengantar</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Pengantar Deep Learning</a></li>
<li class="chapter" data-level="2" data-path="DL.html"><a href="DL.html"><i class="fa fa-check"></i><b>2</b> Konsep Proses Pembelajaran <em>Deep Learning</em></a><ul>
<li class="chapter" data-level="2.1" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i><b>2.1</b> Notasi Matematika</a></li>
<li class="chapter" data-level="2.2" data-path="forwardprop.html"><a href="forwardprop.html"><i class="fa fa-check"></i><b>2.2</b> Konsep Propagasi Maju</a><ul>
<li class="chapter" data-level="2.2.1" data-path="forwardprop.html"><a href="forwardprop.html#inputmat"><i class="fa fa-check"></i><b>2.2.1</b> Matriks Input</a></li>
<li class="chapter" data-level="2.2.2" data-path="forwardprop.html"><a href="forwardprop.html#biasmat"><i class="fa fa-check"></i><b>2.2.2</b> Matriks Bias</a></li>
<li class="chapter" data-level="2.2.3" data-path="forwardprop.html"><a href="forwardprop.html#weightmat"><i class="fa fa-check"></i><b>2.2.3</b> Matriks Bobot</a></li>
<li class="chapter" data-level="2.2.4" data-path="forwardprop.html"><a href="forwardprop.html#active"><i class="fa fa-check"></i><b>2.2.4</b> Fungsi Aktivasi</a></li>
<li class="chapter" data-level="2.2.5" data-path="forwardprop.html"><a href="forwardprop.html#outlayer"><i class="fa fa-check"></i><b>2.2.5</b> <em>Output Layer</em></a></li>
<li class="chapter" data-level="2.2.6" data-path="forwardprop.html"><a href="forwardprop.html#ringkasan-propagasi-maju"><i class="fa fa-check"></i><b>2.2.6</b> Ringkasan Propagasi Maju</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="initialization.html"><a href="initialization.html"><i class="fa fa-check"></i><b>3</b> Inisialisasi Parameter ANN</a></li>
<li class="chapter" data-level="4" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>4</b> Optimasi Model ANN</a></li>
<li class="chapter" data-level="" data-path="referensi.html"><a href="referensi.html"><i class="fa fa-check"></i>Referensi</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Pengenalan Deep Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="forwardprop" class="section level2">
<h2><span class="header-section-number">2.2</span> Konsep Propagasi Maju</h2>
<style>
body{
text-align: justify}
</style>
<p>Input sebuah model ANN dapat berupa apapun. Input dapat berupa intensitas abu-abu (bernilai 0 dan 1) dari sebuah gambar berukuran 30 x 30 pixel. Pada kasus gambar tersebut, kita dapat memiliki 900 unit input atau fitur yang merupakan setiap unit pixel yang dimiliki oleh gambar.</p>
<p>Gambar <a href="forwardprop.html#fig:ANN1">2.2</a> menampilkan contoh ANN dengan 4 fitur, 2 hiden layer dan satu neuron output.</p>
<div class="figure" style="text-align: center"><span id="fig:ANN1"></span>
<img src="images/ANN1.PNG" alt="Contoh ANN dengan 4 fitur, 2 hiden layer dan satu neuron output" width="80%" />
<p class="caption">
Gambar 2.2: Contoh ANN dengan 4 fitur, 2 hiden layer dan satu neuron output
</p>
</div>
<p>Gambar <a href="forwardprop.html#fig:ANN2">2.3</a> menampilkan representasi sebuah proses transformasi data melalui sebuah neuron pada <em>hidden layer</em>.</p>
<div class="figure" style="text-align: center"><span id="fig:ANN2"></span>
<img src="images/ANN2.PNG" alt="Representasi sebuah neuron pada lapisan hidden layer" width="80%" />
<p class="caption">
Gambar 2.3: Representasi sebuah neuron pada lapisan hidden layer
</p>
</div>
<p>Seperti yang telah dijabarkan sebelumnya, pada proses propagasi maju, matks riinput data akan melalui proses perkalian dot terhadap matriks bobotnya (masing-masing input dikalikan dengan bobot dan dijumlahkan seluruhnya). Hasil yang diperoleh selanjutnya dijumlahkan dengan bias. Bias mirip dengan intersep yang ditambahkan dalam persamaan linear. Selain itu, bias merupakan parameter tambahan di ANN yang digunakan untuk menyesuaikan output bersama dengan jumlah bobot input ke neuron. Selain itu, nilai bias memungkinkan kita untuk menggeser fungsi aktivasi ke kanan atau kiri. Dengan demikian, Bias adalah konstanta yang membantu model untuk memproses input data dengan cara yang paling sesuai untuk data yang diberikan. Hasil transformasi data selanjutnya menjadi input bagi <em>layer</em> selanjutnya.</p>
<p>Pada tahapan akhir proses propagasi maju, fungsi <em>cost</em> dihitung dengan membandingkan nilai hasil prediksi dengan nilai aktual serta menghitung nilai jarak antara kedua nilai tersebut. Fungsi <em>cost</em> berguna untuk melihat sejauh mana model ANN menangkap pola dalam data.</p>
<div id="inputmat" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Matriks Input</h3>
<p>Misalkan terdapat sebuah persamaan linier dengan jumlah fitur <span class="math inline">\(n\)</span> :</p>
<p><span class="math display" id="eq:lineq">\[\begin{equation}
y^{\left(i\right)}=w_0+w_1x_1^{\left(i\right)}+w_2x_2^{\left(i\right)}+\cdots+w_nx_n^{\left(i\right)}+\epsilon_i^{\left(i\right)}\ \ untuk\ i=1,\dots,m
  \tag{2.1}
\end{equation}\]</span></p>
<p>Kita dapat merepresentasikan Persamaan <a href="forwardprop.html#eq:lineq">(2.1)</a> ke dalam notasi matriks yang ditunjukkan pada Persamaan <a href="forwardprop.html#eq:lineq2">(2.2)</a></p>
<p><span class="math display" id="eq:lineq2">\[\begin{equation}
\begin{split}
\begin{bmatrix}
y_1 \\[0.3em]
y_2 \\[0.3em]
\vdots \\[0.3em] 
y_m 
\end{bmatrix} &amp; = \begin{bmatrix}
       1       &amp; x_{1}^{\left(1\right)} &amp; x_{1}^{\left(1\right)} &amp; \cdots &amp; x_{n}^{\left(1\right)}           \\[0.3em]
       1       &amp; x_{1}^{\left(2\right)} &amp; x_{1}^{\left(2\right)} &amp; \cdots &amp; x_{n}^{\left(2\right)}           \\[0.3em]
       \vdots  &amp; \vdots                 &amp; \vdots                 &amp; \ddots &amp; \vdots                           \\[0.3em]
       1       &amp; x_{1}^{\left(m\right)} &amp; x_{1}^{\left(m\right)} &amp; \cdots &amp; x_{n}^{\left(m\right)}           \\[0.3em]
     \end{bmatrix}
     
\begin{bmatrix}
w_1 \\[0.3em]
w_2 \\[0.3em]
\vdots \\[0.3em] 
w_m
\end{bmatrix}
     
+ \begin{bmatrix}
\epsilon_1 \\[0.3em]
\epsilon_2 \\[0.3em]
\vdots \\[0.3em] 
\epsilon_m
\end{bmatrix} \\
&amp; = \begin{bmatrix}
w_1 &amp; w_2 &amp; \cdots &amp; w_m 
\end{bmatrix}

\begin{bmatrix}
       1                            &amp; 1                      &amp;  \cdots                &amp; 1                                         \\[0.3em]
       x_{1}^{\left(2\right)}       &amp; x_{1}^{\left(2\right)} &amp; \cdots                 &amp; x_{n}^{\left(m\right)}           \\[0.3em]
       \vdots                       &amp; \vdots                 &amp; \ddots                 &amp; \vdots                                    \\[0.3em]
       x_{n}^{\left(2\right)}       &amp; x_{n}^{\left(2\right)} &amp; \cdots                 &amp; x_{n}^{\left(m\right)}           \\[0.3em]
     \end{bmatrix}
     
+ \begin{bmatrix}
\epsilon_1 \\[0.3em]
\epsilon_2 \\[0.3em]
\vdots \\[0.3em] 
\epsilon_m
\end{bmatrix}
\end{split}
  \tag{2.2}
\end{equation}\]</span></p>
<p>Jika error <span class="math inline">\(\epsilon\)</span> pada Persamaan <a href="forwardprop.html#eq:lineq">(2.1)</a> dan Persamaan <a href="forwardprop.html#eq:lineq2">(2.2)</a> diabaikan maka persamaan yang terbentuk adalah Persamaan <a href="forwardprop.html#eq:lineq3">(2.3)</a>.</p>
<p><span class="math display" id="eq:lineq3">\[\begin{equation}
Y = W^{T} X
  \tag{2.3}
\end{equation}\]</span></p>
<p>Dimensi matriks input berdasarkan Persamaan <a href="forwardprop.html#eq:lineq3">(2.3)</a> adalah <strong>(<em>jumlah fitur</em>, <em>jumlah observasi</em>)</strong>. Misalkan terdapat sebuah model ANN seperti yang ditunjukkan pada Gambar <a href="forwardprop.html#fig:ANN1">2.2</a> dengan 4 fitur dan 2 observasi, maka matriks input pada model tersebut dapat dituliskan sebagai berikut:</p>
<p><span class="math display">\[\begin{equation}
X = \begin{bmatrix}
X_1 &amp; X_2
\end{bmatrix}
= \begin{bmatrix}
x_{1}^{\left(1\right)} &amp; x_{1}^{\left(2\right)} \\[0.3em]
x_{2}^{\left(1\right)} &amp; x_{2}^{\left(2\right)} \\[0.3em]
x_{3}^{\left(1\right)} &amp; x_{3}^{\left(2\right)} \\[0.3em]
x_{4}^{\left(1\right)} &amp; x_{4}^{\left(2\right)} \\[0.3em]
\end{bmatrix}
\end{equation}\]</span></p>
</div>
<div id="biasmat" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Matriks Bias</h3>
<p>Secara umum dimensi matriks bias adalah <strong>(<em>jumlah node pada layer <span class="math inline">\(z^{\left[l\right]}\)</span></em>, <em>1</em>)</strong>. Pada Gambar <a href="forwardprop.html#fig:ANN1">2.2</a>, dimensi matriks bias <em>hidden layer</em> 1 adalah (3,1) karena terdapat 3 buah node pada <em>layer</em> tersebut. Matriks bias pada <em>hidden layer</em> 1 dapat dituliskan sebagai berikut:</p>
<p><span class="math display">\[\begin{equation}
b^{\left[1\right]} = \begin{bmatrix}
r \\[0.3em]
s \\[0.3em]
t
\end{bmatrix}
\end{equation}\]</span></p>
<p>Dimensi matriks bias pada <em>hidden layer</em> 2 dapat dituliskan sebagai berikut;</p>
<p><span class="math display">\[\begin{equation}
b^{\left[1\right]} = \begin{bmatrix}
u \\[0.3em]
v \\[0.3em]
w
\end{bmatrix}
\end{equation}\]</span></p>
</div>
<div id="weightmat" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Matriks Bobot</h3>
<p>Dimensi matriks bobot ditentukan oleh jumlah node pada layer awal dan pada layer selanjutnya. Sebagai Contoh pada Gambar <a href="forwardprop.html#fig:ANN1">2.2</a>, matriks bobot dari <em>input layer</em> menuju <em>hidden layer</em> 1 memiliki dimensi (4,2), matriks bobot dari <em>hidden layer</em> 1 menuju <em>hidden layer</em> 2 memiliki dimensi (3,3), dan matriks bobot dari <em>hidden layer</em> 2 menuju <em>output layer</em> memiliki dimensi (3,1). Berdasarkan contoh tersebut, dimensi matriks bobot dapat digeneralisasi menjadi <strong>(<em>jumlah node ke-(l-1)</em>, <em>jumlah node ke-l</em>)</strong>.</p>
</div>
<div id="active" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Fungsi Aktivasi</h3>
<p>Setelah dilakukan penambahan bias pada hasil perkalian titik, generalisasi proses perkalian titik input pada tiap <em>hidden layer</em> dapat dinyatakan melalui Persamaan <a href="forwardprop.html#eq:active1">(2.4)</a>:</p>
<p><span class="math display" id="eq:active1">\[\begin{equation}
Z^{\left[l\right]}=W^{\left[l\right]T} A^{\left[l-1\right]} + b^{\left[l\right]}
  \tag{2.4}
\end{equation}\]</span></p>
<p>Sebagai contoh perkalian titik pada <em>hidden layer</em> 1 berdasarkan Gambar <a href="forwardprop.html#fig:ANN1">2.2</a> dapat dituliskan sebagai berikut:</p>
<p><span class="math display" id="eq:active1">\[\begin{equation}
Z^{\left[1\right]}=W^{\left[1\right]T} X + b^{\left[1\right]}
  \tag{2.4}
\end{equation}\]</span></p>
<p>dimana <span class="math inline">\(X\)</span> merupakan input pada <em>hidden layer</em> 1, dan <span class="math inline">\(Z^{\left[l\right]}\)</span> merupakan input menuju <em>hidden layer</em> selanjutnya.</p>
<p>Secara umum <span class="math inline">\(Z^{\left[l\right]}\)</span> memiliki dimensi <strong>(<em>jumlah node pada hidden layer l</em>, <em>jumlah observasi</em>)</strong>. Pada contoh input pada Gambar <a href="forwardprop.html#fig:ANN1">2.2</a>, <span class="math inline">\(Z^{\left[1\right]}\)</span> memiliki dimensi (3,2).</p>
<p>Persamaan <span class="math inline">\(Z^{\left[1\right]}\)</span> dapat dituliskan ke dalam notasi matriks berikut:</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
Z^{\left[1\right]} &amp; =

\begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} \\[0.3em]
w_{21} &amp; w_{22} &amp; w_{23} \\[0.3em]
w_{31} &amp; w_{32} &amp; w_{33} \\[0.3em]
w_{41} &amp; w_{42} &amp; w_{43}
\end{bmatrix}

\begin{bmatrix}
x_{1}^{\left(1\right)} &amp; x_{1}^{\left(2\right)} \\[0.3em]
x_{2}^{\left(1\right)} &amp; x_{2}^{\left(2\right)} \\[0.3em]
x_{3}^{\left(1\right)} &amp; x_{3}^{\left(2\right)} \\[0.3em]
x_{4}^{\left(1\right)} &amp; x_{4}^{\left(2\right)} \\[0.3em]
\end{bmatrix}

+

\begin{bmatrix}
r \\[0.3em]
s \\[0.3em]
t
\end{bmatrix}

&amp; = \begin{bmatrix}
z_{1,1}^{\left[1\right]} &amp; z_{1,2}^{\left[1\right]} \\[0.3em]
z_{2,1}^{\left[1\right]} &amp; z_{2,2}^{\left[1\right]} \\[0.3em]
z_{3,1}^{\left[1\right]} &amp; z_{3,2}^{\left[1\right]} \\[0.3em]
\end{bmatrix}

\end{split}
\end{equation}\]</span></p>
<p>Fungsi aktivasi <span class="math inline">\(A^{\left[1\right]}\)</span> memiliki dimensi yang sama dengan <span class="math inline">\(Z^{\left[1\right]}\)</span> dan dituliskan ke dalam notasi matriks berikut:</p>
<p><span class="math display">\[\begin{equation}
\begin{bmatrix}
g\left(z_{1,1}^{\left[1\right]}\right) &amp; g\left(z_{1,2}^{\left[1\right]}\right) \\[0.3em]
g\left(z_{2,1}^{\left[1\right]}\right) &amp; g\left(z_{2,2}^{\left[1\right]}\right) \\[0.3em]
g\left(z_{3,1}^{\left[1\right]}\right) &amp; g\left(z_{3,2}^{\left[1\right]}\right) \\[0.3em]
\end{bmatrix}
\end{equation}\]</span></p>
<p>dimana <span class="math inline">\(g\)</span> merupakan sebuah fungsi aktivasi (contoh: sigmoid, linier, dll.).</p>
<p>Matriks <span class="math inline">\(A^{\left[1\right]}\)</span> selanjutnya menjadi matriks input pada <em>hidden layer</em> 2. Perkalian titik pada <em>hidden layer</em> 2 dapat dituliskan ke dalam persamaan berikut:</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
Z^{\left[2\right]} &amp; = W^{\left[2\right]T} A^{\left[1\right]} + b^{\left[2\right]}

&amp; = \begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} \\[0.3em]
w_{21} &amp; w_{22} &amp; w_{23} \\[0.3em]
w_{31} &amp; w_{32} &amp; w_{33} 
\end{bmatrix}

\begin{bmatrix}
g\left(z_{1,1}^{\left[1\right]}\right) &amp; g\left(z_{1,2}^{\left[1\right]}\right) \\[0.3em]
g\left(z_{2,1}^{\left[1\right]}\right) &amp; g\left(z_{2,2}^{\left[1\right]}\right) \\[0.3em]
g\left(z_{3,1}^{\left[1\right]}\right) &amp; g\left(z_{3,2}^{\left[1\right]}\right) \\[0.3em]
\end{bmatrix}

+ bias^{\left[2\right]}

\end{split}
\end{equation}\]</span></p>
<p>Fungsi aktivasi berdasarkan input <span class="math inline">\(Z^{\left[2\right]}\)</span> adalah sebagai berikut:</p>
<p><span class="math display">\[\begin{equation}
A^{\left[2\right]} =
\begin{bmatrix}
g\left(z_{1,1}^{\left[2\right]}\right) &amp; g\left(z_{1,2}^{\left[2\right]}\right) \\[0.3em]
g\left(z_{2,1}^{\left[2\right]}\right) &amp; g\left(z_{2,2}^{\left[2\right]}\right) \\[0.3em]
g\left(z_{3,1}^{\left[2\right]}\right) &amp; g\left(z_{3,2}^{\left[2\right]}\right) \\[0.3em]
\end{bmatrix}
\end{equation}\]</span></p>
<p>Layer terakhir pada skema model yang ditunjukkan pada Gambar <a href="forwardprop.html#fig:ANN1">2.2</a> adalah <em>output layer</em>. Perkalian titik input pada <em>layer</em> tersebut adalah sebagai berikut:</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
Z^{\left[3\right]} &amp; = W^{\left[3\right]T} A^{\left[2\right]} + b^{\left[3\right]}

&amp; = \begin{bmatrix}
w_{11}  \\[0.3em]
w_{21}  \\[0.3em]
w_{31}  
\end{bmatrix}

\begin{bmatrix}
g\left(z_{1,1}^{\left[2\right]}\right) &amp; g\left(z_{1,2}^{\left[2\right]}\right) \\[0.3em]
g\left(z_{2,1}^{\left[2\right]}\right) &amp; g\left(z_{2,2}^{\left[2\right]}\right) \\[0.3em]
g\left(z_{3,1}^{\left[2\right]}\right) &amp; g\left(z_{3,2}^{\left[2\right]}\right) \\[0.3em]
\end{bmatrix}

+ bias^{\left[3\right]}

\end{split}
\end{equation}\]</span></p>
<p>Berdasarkan <span class="math inline">\(Z^{\left[3\right]}\)</span>, dimensi A^{} adalah (1, 3).</p>
<p><span class="math display">\[\begin{equation}
A^{\left[3\right]} =
\begin{bmatrix}
g\left(z_{1,1}^{\left[3\right]}\right) &amp; g\left(z_{1,2}^{\left[3\right]}\right)
\end{bmatrix}
\end{equation}\]</span></p>
</div>
<div id="outlayer" class="section level3">
<h3><span class="header-section-number">2.2.5</span> <em>Output Layer</em></h3>
<p>Berdasarkan hasil pembahasan sebelumnya, output dari model diperoleh melalui matriks A^{}. Pada kasus klasifikasi biner, nilai tiap elemen merupakan nilai probabilitas. Pelabelan output selanjutnya dilakukan dengan menetapkan sejumlah batas, seperti: jika <span class="math inline">\(\ge 0,5\)</span> maka labelnya adalah 1, dan jika $ &lt; 0,5$ maka labelnya adalah 0.</p>
</div>
<div id="ringkasan-propagasi-maju" class="section level3">
<h3><span class="header-section-number">2.2.6</span> Ringkasan Propagasi Maju</h3>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="notation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="initialization.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
